version: "3"

# Define the Docker volume named esdata for the Elasticsearch container.
volumes:
  esdata:

# Deploying three container services (fluentd, elasticsearch, and kibana)
services:
  # Deploy using the custom image automatically be created during the build process.
  fluentd: 
    build: ./fluentd
    links: # Sends incoming logs to the elasticsearch container.
      - elasticsearch
    depends_on:
      - elasticsearch
    ports: # Exposes the port 24224 on both TCP and UDP protocol for log aggregation
      - 24224:24224
      - 24224:24224/udp
      - 9880:9880

  # Created using the Docker image elasticsearch:7.17.0
  elasticsearch:
    image: elasticsearch:7.17.0
    expose: # Exposes the default port 9200
      - 9200
    environment:
      - discovery.type=single-node # Runs as a single-node
    volumes: # Stores elasticsearch data locally on the esdata Docker volume
      - ./elasticsearch/esdata:/usr/share/elasticsearch/data

  # Created using the Docker image kibana:7.17.0
  kibana:
    image: kibana:7.17.0
    links: # Links kibana service to the elasticsearch container
      - elasticsearch
    depends_on:
      - elasticsearch
    ports: # Runs kibana service on default port 5601
      - 5601:5601
    environment: # Defined host configuration
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

  # After configuring the Kibana index pattern, youâ€™ll run a Docker container with Fluentd log drive, automatically sending logs to the EFK stack. In this case NGINX.
  nginx:
    image: nginx:alpine
    restart: always
    links:
      - fluentd
    depends_on:
      - fluentd
    ports: # Runs nginx service on port 8080
      - 8090:80
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        fluentd-async-connect: "true"
        tag: nginx-docker
    

